{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KAVINESH23/Medical-Image-Captioning/blob/main/Miniproject%20GIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01fGsLj1e1Tl",
        "outputId": "760baf0a-156b-469e-82aa-2a69ad1866a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from transformers import AutoImageProcessor, AutoTokenizer\n",
        "\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_images_and_captions(image_dir, caption_dir, image_processor, tokenizer):\n",
        "    images, captions = [], []\n",
        "\n",
        "    # Loop through all the images in the image directory\n",
        "    for image_name in os.listdir(image_dir): # image_dir is expected to be a single directory path\n",
        "        if image_name.endswith('.jpg') or image_name.endswith('.png'):  # Make sure it's an image file\n",
        "            # Load the image\n",
        "            image_path = os.path.join(image_dir, image_name)\n",
        "            image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
        "\n",
        "            # Process image using the image processor\n",
        "            pixel_values = image_processor(image, return_tensors=\"pt\").pixel_values.squeeze(0)\n",
        "\n",
        "            # Read the corresponding caption from the caption directory\n",
        "            caption_file = os.path.join(caption_dir, f'{os.path.splitext(image_name)[0]}.txt')\n",
        "            if os.path.exists(caption_file):\n",
        "                with open(caption_file, 'r') as f:\n",
        "                    caption = f.read().strip()\n",
        "            else:\n",
        "                caption = \"\"  # In case the caption file is missing\n",
        "\n",
        "            # Append the image and caption to the lists\n",
        "            images.append(pixel_values)\n",
        "            captions.append(caption)\n",
        "\n",
        "    return images, captions\n",
        "\n",
        "class ImageCaptionDataset(Dataset):\n",
        "    def __init__(self, image_dirs, caption_dirs, image_processor, tokenizer): # Now accepts lists of directories\n",
        "        self.image_processor = image_processor\n",
        "        self.tokenizer = tokenizer\n",
        "        self.images, self.captions = [], []\n",
        "\n",
        "        # Iterate through each image and caption directory\n",
        "        for image_dir, caption_dir in zip(image_dirs, caption_dirs):\n",
        "            # Call preprocess_images_and_captions for each directory pair\n",
        "            images, captions = preprocess_images_and_captions(image_dir, caption_dir, image_processor, tokenizer)\n",
        "            self.images.extend(images) # Extend the lists with data from each directory\n",
        "            self.captions.extend(captions)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        caption = self.captions[idx]\n",
        "        # Tokenize the caption\n",
        "        encoding = self.tokenizer(caption, padding='max_length', truncation=True, max_length=50, return_tensors=\"pt\")\n",
        "        return image, encoding.input_ids.squeeze(0), encoding.attention_mask.squeeze(0)\n",
        "\n",
        "# Initialize dataset and dataloaders\n",
        "image_dirs = [ # Updated to image_dirs\n",
        "    \"/content/drive/MyDrive/radio_train\",\n",
        "    \"/content/drive/MyDrive/radio_validate\",\n",
        "    \"/content/drive/MyDrive/radio_test\"\n",
        "]\n",
        "caption_dirs = [ # Updated to caption_dirs\n",
        "    \"/content/drive/MyDrive/radio_traincaption\",\n",
        "    \"/content/drive/MyDrive/radio_validatecaption\",\n",
        "    \"/content/drive/MyDrive/radio_testcaption\"\n",
        "]\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/git-base\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/git-base\")\n",
        "\n",
        "# Pass the image_processor and tokenizer objects to the ImageCaptionDataset constructor\n",
        "dataset = ImageCaptionDataset(image_dirs, caption_dirs, image_processor, tokenizer)"
      ],
      "metadata": {
        "id": "tLvxembAmMbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "p663Q87urcaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --upgrade # Make sure transformers is up to date\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoImageProcessor, AutoTokenizer # Use AutoModelForCausalLM\n",
        "\n",
        "# Initialize the model using GitForCausalLM\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/git-base\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m27t2M1TqOWA",
        "outputId": "6d5e798e-187f-4a49-a5cb-e5c070f6b807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Move model to device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (images, input_ids, attention_masks) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_masks = attention_masks.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        # Pass input_ids as input to the model along with pixel_values and labels\n",
        "        outputs = model(pixel_values=images, input_ids=input_ids, labels=input_ids)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC41zj5mqHnd",
        "outputId": "96c7daed-badd-4a37-daa0-abe4c244b019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 2.8916\n",
            "Epoch 2/5, Loss: 2.0427\n",
            "Epoch 3/5, Loss: 1.7769\n",
            "Epoch 4/5, Loss: 1.5690\n",
            "Epoch 5/5, Loss: 1.3834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot thre model loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have a list called 'losses' that stores the loss values from each epoch\n",
        "# Replace this with your actual loss values\n",
        "losses = [2.89, 2.04, 1.77,1.56,1.34]\n",
        "\n",
        "epochs = range(1, len(losses) + 1)\n",
        "\n",
        "plt.plot(epochs, losses, marker='o', linestyle='-')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "8IvajHVC3U2J",
        "outputId": "828d9bdd-1542-4771-a801-83737b3ad0bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: perform bleu score based on model training\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "# Evaluation loop (after training)\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "references = []\n",
        "candidates = []\n",
        "\n",
        "# Assuming you have a test_loader for the test data\n",
        "# Replace this with your actual test_loader\n",
        "test_loader = DataLoader(dataset, batch_size=1) # Use the same dataset for simplicity\n",
        "smoothie = SmoothingFunction().method4\n",
        "\n",
        "for batch_idx, (images, input_ids, attention_masks) in enumerate(test_loader):\n",
        "    images = images.to(device)\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_masks = attention_masks.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Generate captions\n",
        "        generated_ids = model.generate(pixel_values=images, max_length=50)\n",
        "\n",
        "    # Decode the generated captions and references\n",
        "    generated_caption = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "    reference_caption = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    candidates.append(generated_caption.split()) # split the generated caption to words\n",
        "    references.append([reference_caption.split()]) # split the reference caption to words\n",
        "\n",
        "\n",
        "bleu_scores = []\n",
        "for i in range(len(candidates)):\n",
        "  bleu_scores.append(sentence_bleu(references[i], candidates[i], smoothing_function = smoothie))\n",
        "\n",
        "# Calculate the average BLEU score\n",
        "average_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "\n",
        "print(f\"Average BLEU score: {average_bleu:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "CxrIVKTW68bZ",
        "outputId": "d3cff70d-a022-4b79-aeeb-7405d238143a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-62a5c02f2c6c>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Evaluation loop (after training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set the model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print model accuracy\n",
        "\n",
        "# Assuming 'avg_loss' is defined in your training loop\n",
        "print(f\"Final Average Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy8Y1oX_6lZx",
        "outputId": "12cd9e94-ce87-48c1-904e-0c8d60048cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Average Loss: 1.0729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save model for deployment\n",
        "\n",
        "import torch\n",
        "\n",
        "# Save the model's state dictionary\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/radiology_model.pth')\n",
        "\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ9S1VNn3ded",
        "outputId": "21518709-26b5-410b-c5ff-c7db8175a9cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save model in h5\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained('/content/drive/MyDrive/radiology_model_h5')\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBP3kKdc3mQL",
        "outputId": "1a47ac79-f781-479f-ce8b-053b09311f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "def compute_bleu_ngram(predictions, references, ngram_order=4):\n",
        "    chencherry = SmoothingFunction()\n",
        "    bleu_scores = []\n",
        "\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        # Convert the tensor to a string before splitting\n",
        "        ref_split = ref.cpu().numpy().tolist()\n",
        "        ref_split = tokenizer.decode(ref_split).split()  # reference caption (one reference)\n",
        "\n",
        "        pred_split = pred.split()  # predicted caption\n",
        "\n",
        "        # Compute BLEU score for the specific n-gram order\n",
        "        bleu_scores.append(sentence_bleu([ref_split], pred_split, weights=[1.0/ngram_order] * ngram_order, smoothing_function=chencherry.method1))\n",
        "\n",
        "    # Average BLEU score\n",
        "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "    return avg_bleu\n",
        "\n",
        "# Assuming `predictions` and `references` are lists of strings\n",
        "bleu_score_4 = compute_bleu_ngram(predictions, references, ngram_order=4)\n",
        "print(f\"BLEU-4 Score: {bleu_score_4:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T18CwF2y5lB",
        "outputId": "64562745-2539-425f-f5cb-598c28a23d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-4 Score: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "\n",
        "# Use a smoothing function to avoid zero BLEU score for small overlaps\n",
        "smooth = SmoothingFunction().method4\n",
        "\n",
        "# Compute BLEU score with smoothing\n",
        "bleu_score = corpus_bleu(ref_tokens, pred_tokens, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smooth)\n",
        "print(f\"Smoothed BLEU-4 Score: {bleu_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyKD2tNJ0jHZ",
        "outputId": "5b21eed9-7ede-4954-cbf8-4be4167b4d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoothed BLEU-4 Score: 0.0139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score # Install the rouge-score package"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz7WKcS90-1Q",
        "outputId": "bdd07e5a-daf0-4654-f719-f6e97b6b8e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.6)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=fa04e65628a97cea69d2d0f499771dd2413dec7acc1c824c0af17be2c3ba536e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "\n",
        "# Example for a single prediction-reference pair\n",
        "pred_caption = \"ct scan of abdomen showing a mass in the right upper lobe ( arrow )\"\n",
        "ref_caption = \"ct scan shows a mass in the right upper quadrant of the abdomen\"\n",
        "\n",
        "scores = scorer.score(ref_caption, pred_caption)\n",
        "print(f\"ROUGE-1 Score: {scores['rouge1']}\")\n",
        "print(f\"ROUGE-L Score: {scores['rougeL']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUaSwI6O0jEe",
        "outputId": "3ca456a7-728d-4cc0-abb3-bbd771f9ce7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-1 Score: Score(precision=0.8461538461538461, recall=0.8461538461538461, fmeasure=0.8461538461538461)\n",
            "ROUGE-L Score: Score(precision=0.6923076923076923, recall=0.6923076923076923, fmeasure=0.6923076923076923)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming references_train and predictions_train are lists of strings\n",
        "references_train = [\"A CT scan showing a mass in the abdomen.\"]\n",
        "predictions_train = [\"The CT scan shows a mass in the abdomen.\"]\n",
        "\n",
        "references_val = [\"An X-ray of the chest showing signs of pneumonia.\"]\n",
        "predictions_val = [\"Chest X-ray indicates possible pneumonia.\"]\n",
        "\n",
        "references_test = [\"MRI scan shows a lesion in the left temporal lobe.\"]\n",
        "predictions_test = [\"The MRI reveals a lesion in the left temporal lobe.\"]\n",
        "\n",
        "# Tokenizing references and predictions for BLEU\n",
        "decoded_references_train = [[ref.split()] for ref in references_train]\n",
        "decoded_predictions_train = [pred.split() for pred in predictions_train]\n",
        "\n",
        "decoded_references_val = [[ref.split()] for ref in references_val]\n",
        "decoded_predictions_val = [pred.split() for pred in predictions_val]\n",
        "\n",
        "decoded_references_test = [[ref.split()] for ref in references_test]\n",
        "decoded_predictions_test = [pred.split() for pred in predictions_test]\n",
        "\n",
        "# BLEU-4 Score for training set\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "smoothie = SmoothingFunction().method1\n",
        "\n",
        "bleu_train = [sentence_bleu(refs, pred, smoothing_function=smoothie)\n",
        "              for refs, pred in zip(decoded_references_train, decoded_predictions_train)]\n",
        "bleu_val = [sentence_bleu(refs, pred, smoothing_function=smoothie)\n",
        "            for refs, pred in zip(decoded_references_val, decoded_predictions_val)]\n",
        "bleu_test = [sentence_bleu(refs, pred, smoothing_function=smoothie)\n",
        "             for refs, pred in zip(decoded_references_test, decoded_predictions_test)]\n",
        "\n",
        "# Print average BLEU-4 scores\n",
        "print(f\"Training BLEU-4 Score: {sum(bleu_train) / len(bleu_train):.4f}\")\n",
        "print(f\"Validation BLEU-4 Score: {sum(bleu_val) / len(bleu_val):.4f}\")\n",
        "print(f\"Test BLEU-4 Score: {sum(bleu_test) / len(bleu_test):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozR1lcl-1lHq",
        "outputId": "f436e7d8-4076-4592-b798-f84bed11addf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training BLEU-4 Score: 0.5133\n",
            "Validation BLEU-4 Score: 0.0287\n",
            "Test BLEU-4 Score: 0.6606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k32d72gi187_",
        "outputId": "3238ce15-ddcd-46d5-deb0-240700cbeb36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GitForCausalLM(\n",
              "  (git): GitModel(\n",
              "    (embeddings): GitEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(1024, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (image_encoder): GitVisionModel(\n",
              "      (vision_model): GitVisionTransformer(\n",
              "        (embeddings): GitVisionEmbeddings(\n",
              "          (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
              "          (position_embedding): Embedding(197, 768)\n",
              "        )\n",
              "        (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (encoder): GitVisionEncoder(\n",
              "          (layers): ModuleList(\n",
              "            (0-11): 12 x GitVisionEncoderLayer(\n",
              "              (self_attn): GitVisionAttention(\n",
              "                (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              )\n",
              "              (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (mlp): GitVisionMLP(\n",
              "                (activation_fn): QuickGELUActivation()\n",
              "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              )\n",
              "              (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (encoder): GitEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x GitLayer(\n",
              "          (attention): GitAttention(\n",
              "            (self): GitSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): GitSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): GitIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): GitOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (visual_projection): GitProjection(\n",
              "      (visual_projection): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (output): Linear(in_features=768, out_features=30522, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from transformers import AutoTokenizer, AutoProcessor\n",
        "\n",
        "# Load your desired image processor\n",
        "processor = AutoProcessor.from_pretrained(\"microsoft/git-base\") # Replace with your model name\n",
        "\n",
        "# Define the preprocessing function\n",
        "def preprocess_images_and_captions(image):\n",
        "    # Process the image using your processor\n",
        "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
        "\n",
        "    return pixel_values\n",
        "\n",
        "# Load and preprocess an image\n",
        "image_path = \"/content/lung.jpeg\"\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "processed_image = preprocess_images_and_captions(image)\n",
        "\n",
        "# Convert image to the format expected by the model\n",
        "input_tensor = processed_image.unsqueeze(0)  # Add batch dimension"
      ],
      "metadata": {
        "id": "QHqqi9Na2w-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    # Ensure input_ids has the expected shape (batch_size, sequence_length)\n",
        "    # You might need to reshape or process input_tensor to obtain the correct input_ids\n",
        "    # Example: If input_tensor represents an image, you may need to encode it\n",
        "    # into a sequence of tokens using the model's encoder before generating text.\n",
        "\n",
        "    # Assuming you have a way to get input_ids from input_tensor:\n",
        "    # input_ids = model.get_input_embeddings(input_tensor) # Or a similar method\n",
        "\n",
        "    # Reshape to (batch_size, sequence_length) if necessary\n",
        "    # input_ids = input_ids.view(input_ids.size(0), -1)\n",
        "\n",
        "    outputs = model.generate(inputs=input_ids, max_new_tokens=50, num_beams=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahIyBSoS29R3",
        "outputId": "b5b3e664-827e-4e19-999a-e2b69082076e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the output to get the caption\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/git-base\")\n",
        "caption = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Generated Caption:\", caption)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OzxQABG3FDx",
        "outputId": "5271f2e1-d7c2-4a50-ef54-526686663a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption: image id : rocov2 _ 2023 _ train _ 001316 caption : ct showing resolution of the hepatic portal venous gas ( case 1 ).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5schO5hs3KZi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}